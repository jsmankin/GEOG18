{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DIFUSE_GEOG36_PS2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMLbd/00mHaCjbspzuvuAXf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rkQwXYTGdrM4","colab_type":"text"},"source":["# Problem Set #2 \n","\n","Python is open source, which means that it is free, and anyone can alter its source code. You can't do that with [Matlab](https://www.mathworks.com/products/matlab.html), for example, which is kind of like a [\"walled garden\"](https://twitter.com/gallantlab/status/1014680265711501312) that only wealthy people can enjoy. \n","\n","In the last problem set, we explored basic data types and functions embedded within Python. Because Python is open source, smart folks have taken the language and written a bunch of highly-optimized functions and methods to do certain tasks. These people then compile these functions into things called \"libraries.\"\n","\n","Libraries are therefore a collection of functions and methods, often called [modules](https://docs.python.org/3/library/) that allows you to perform lots of actions without having to write your own code. In nearly all of the code above, we were using base libraries that come in Python called the standard library. \n","\n","### **Learning objectives:**\n","1. Learn how to use open source packages\n","2. Explore additional data structures in Python\n","\n","In the lectures, we learned about how there can be discrepancies from different disaster reporting agencies from differing motivations on collecting data. In this problem set, we will be using data from those agencies to explore additional data structures in Python. \n","\n","\n","**Total points for this problem set: 27 pts**\n","*   Example codes executed: 5 pts\n","*   Correct answers to problems: 17 pts\n","*   Comments added to responses: 5 pts\n","\n","**Please do not forget to add comments (with the # sign) next to your code for all of the problems to explain what you are doing.**"]},{"cell_type":"markdown","metadata":{"id":"KZodzXbJeW-g","colab_type":"text"},"source":["## #1. Numpy\n","\n","[Numpy](https://docs.scipy.org/doc/numpy-1.13.0/user/whatisnumpy.html) is a library. Click on the link and take a look. The documentation for numpy, which is one of the most important Python libraries, is crucial. Part of learning coding is building your confidence navigating the documentation associated with coding libraries."]},{"cell_type":"code","metadata":{"id":"WlEfhkU0fGYJ","colab_type":"code","colab":{}},"source":["# import numpy with as Python object named np\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HEiPn4e_gG8A","colab_type":"text"},"source":["## 1.1 NDArrays and additional data types\n","\n","The core class (i.e., the \"blueprint\") of Numpy, which is just a library of code produced by people to do things, is this thing called an numpy ndarray (n-dimensional array). \n","\n","Here, the \"n\" just means a countable positive numberâ€”it can be 1, 2, 3, ..., n. The word [array](https://en.wikipedia.org/wiki/Array_data_structure) just refers to the way the data is arranged, kind of like in an Excel table. \n","\n","For example, that weather map we want to plot, if it's just something like surface temperature, is a 2-dimensional array, one dimension for latitude, one dimension for longitude. So each row in the array might corresppond to a different line of longitude, and all the columns might represent different lines of latitude. Then the values in the table would be the temperature at that latitude and longitude pair.\n","\n","If we want to make multiple maps showing how temperature evolves over time, it could be stored as a 3-dimensional array: latitude, longitude, and time. So this ndarray thing is just a new type of data class, just like the string class from the first problem set. See the image below."]},{"cell_type":"code","metadata":{"id":"1q3evMJ5cJC-","colab_type":"code","colab":{}},"source":["from IPython.display import Image\n","Image(url='https://cdn-images-1.medium.com/max/2400/1*Ikn1J6siiiCSk4ivYUhdgw.png')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtkqWqGhf6FI","colab_type":"code","colab":{}},"source":["# Let's create an array from a list\n","a = np.array([3,5,2,8,1])\n","\n","# Notice the square brackets [] creating the list inside the function np.array(),\n","# where np is the name of the oject containing the numpy library and the \"dot\" (.) allows us to access functions or methods from that library.\n","# So here it's saying, use the \"array\" function in the numpy library"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdbihxpHgHHF","colab_type":"code","colab":{}},"source":["# What is the shape?\n","a.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1TC-ppo6gQe9","colab_type":"code","colab":{}},"source":["# What is the shape type?\n","type(a.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amlBAV1whZvQ","colab_type":"code","colab":{}},"source":["# What is the datatype?\n","a.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQC1COqahd9c","colab_type":"text"},"source":["Data types are pretty crucial. Essentially, a data type just limits the values a given variable or object can take on. We've met a few data types already: 1. strings, 2. numbers, 3. dictionaries, 4. booleans, 5. tuples. \n","\n","Some other specific datatypes include:\n","1. Integers (`int`)\n","2. Booleans (`bool`)\n","3. Real (`float`)\n","4. Complex (`complex`)\n","\n","Above, it says, the data type is 'int64'. What exactly does this mean? \n","\n","So above I made the elements of the `numpy` array (ndarray) a double-precision (64-bit) float. \n","\n","It specifies how precise I want the computer to be with the numbers.\n","\n","Precision is crucial in climate science. One of the interesting challenges in climate modeling\n","is that if I take a climate model, which is based on a set of deterministic equations (mass, momentum, energy), I will get a different answer on one computer than another computer, even if I provide the model with the same starting point (what we call _initial conditions_). This is because different computers generate round-off errors in their storage of floating point numbers. \n","\n","[Watch the great (and patient) Salman Khan explain binary](https://www.youtube.com/watch?v=ku4KOFQ-bB4), and once you've done that, watch the [fantastic Computerphile piece on floating point numbers](https://www.youtube.com/watch?v=PZRI1IfStY0). "]},{"cell_type":"code","metadata":{"id":"oyCSllr-isyn","colab_type":"code","colab":{}},"source":["# Here is an array with a different datatype and shape\n","b = np.array([[3,4,8,5], [0,2,6,1]], dtype= np.float64)\n","\n","# View\n","b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u8__guWvi7sk","colab_type":"code","colab":{}},"source":["# Let's check datatype and shape\n","b.dtype, b.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPrT_BKujjg4","colab_type":"code","colab":{}},"source":["# Arrays can be easily created with numpy\n","# Let's create a 9 x 9 array with just 0's \n","zero_array = np.zeros((9,9))\n","\n","print(zero_array)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P0Wo49oyj4I1","colab_type":"code","colab":{}},"source":["# We can also create an array with ranges\n","np.arange(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q-5z6Bw9NxNZ","colab_type":"text"},"source":["### Problem #1\n","\n","Let's create arrays on disaster data from 1996 to 2016 as reported by Sigma.\n","\n","Here is the table of # of disasters and # of victims:\n","\n","|   Year    | # of disasters| # of victims |\n","|:------:|:------:|:------: |\n","| 1996 | \t312\t|\t21276 |\n","| 1997 |\t303\t|\t23323 |\n","| 1998 | 297 | \t45416 |\n","| 1999 | 296 | 62846 |\n","| 2000 | \t299\t |\t14950 |\n","| 2001 | \t298\t |\t35609 |\n","| 2002 | \t287\t|\t22311 |\n","| 2003 | \t322\t|\t78894 |\n","| 2004 | \t355\t|\t242519 |\n","| 2005 | \t421\t|\t101563 |\n","| 2006 | \t367\t|\t32532 |\n","| 2007 | \t360\t|\t22199 |\n","| 2008 | \t334\t|\t240612 |\n","| 2009 | \t308\t|\t14948 |\n","| 2010 | \t345\t|\t304054 |\n","| 2011 | \t341\t|\t34072 |\n","| 2012 | \t326\t|\t14007 |\n","| 2013 | \t327\t|\t27063 |\n","| 2014 | \t344\t|\t12914 |\n","| 2015 | \t357\t|\t26543 |\n","| 2016 | \t355\t|\t10841 |\n","\n","We want to save the data from this table as a Python object we can work with."]},{"cell_type":"markdown","metadata":{"id":"1VVE3aJuGoBI","colab_type":"text"},"source":["1A - Create one array with two separate lists for the number of disasters and number of victims. Print the array.\n","\n","Hint: Think about what datatype you would like to use for this array."]},{"cell_type":"code","metadata":{"id":"Hhz3JRj_P75O","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EgwpVm4lGuDR","colab_type":"text"},"source":["1B - What is the shape of the data?"]},{"cell_type":"code","metadata":{"id":"uMzs3HFBcOA1","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KVP2NL4VgVHZ","colab_type":"text"},"source":["## 1.2 Indexing and Slicing\n","\n","Indexing is how we pull individual data items out of an array. Slicing extends this process to pulling out a regular set of the items.\n","\n","Keep in mind that Python uses a zero-based system."]},{"cell_type":"code","metadata":{"id":"gjNwc_nZlHFw","colab_type":"code","colab":{}},"source":["# Let's create a practice array\n","# I am creating an array with numbers from 1 through 12 that has a 3 by 4 dimensionality\n","A = np.arange(12).reshape(3,4)\n","\n","A"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZ3Q8YPklUlK","colab_type":"code","colab":{}},"source":["# How can we find the 2nd item along the first dimension (row) and the 3rd along the second dimension (column)\n","# Is the below code correct? \n","A[2, 3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XlJsRkidlumB","colab_type":"code","colab":{}},"source":["# No, it is not! Because it is a zero-based system, we have to adjust accordingly\n","# The correct answer will be\n","A[1,2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UfigDa7BmZ6Z","colab_type":"code","colab":{}},"source":["# We can also index one whole dimension\n","# Here is the first dimension:\n","A[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mkSIW1-ImZPV","colab_type":"text"},"source":["Negative indices are also allowed, which permit indexing relative to the end of the array."]},{"cell_type":"code","metadata":{"id":"KSrVHfKPmmmL","colab_type":"code","colab":{}},"source":["A[0,-1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4SBOA0m0mqcd","colab_type":"text"},"source":["Slicing syntax is written as `start:stop[:step]`, where all numbers are optional.\n","- defaults: \n","  - start = 0\n","  - stop = len(dim)\n","  - step = 1\n","- The second colon is also optional if no step is used.\n","\n","It should be noted that end represents one past the last item; one can also think of it as a half open interval: `[start, end)`"]},{"cell_type":"code","metadata":{"id":"bxFzrZLHmsY5","colab_type":"code","colab":{}},"source":["# Get the 2nd and 3rd rows\n","A[1:3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0h0grq57mvUS","colab_type":"code","colab":{}},"source":["# All rows and 3rd column\n","A[:, 2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMEj5IRnmy5h","colab_type":"code","colab":{}},"source":["# ... can be used to replace one or more full slices\n","A[..., 2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J08nPwiKnUhH","colab_type":"text"},"source":["### Problem #2\n","\n","Let's practice indexing and shaping data from the array you made in Problem #1. "]},{"cell_type":"code","metadata":{"id":"cPvRKUeffzT2","colab_type":"code","colab":{}},"source":["# Print the array you produced in Problem #1\n","\n","# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9IQwh3twG2LV","colab_type":"text"},"source":["2A - What is the # of disasters that is located in the 10th year on record?\n","\n"]},{"cell_type":"code","metadata":{"id":"ThUHOybzQuzR","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SZhIa1IDG49K","colab_type":"text"},"source":["2B - # What is the # of victims that happened in each of the last five years?\n","\n"]},{"cell_type":"code","metadata":{"id":"5kADPUEoQ_bP","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dLtvV3ThG7Al","colab_type":"text"},"source":["2C - Reshape the array into a new object, so that it has seven years of only the number of disasters per list in the array. Print the new object to see that it is formatted correctly.\n"]},{"cell_type":"code","metadata":{"id":"Jd-6kYf-RYYz","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32XfTt8agr-9","colab_type":"text"},"source":["## 1.3 Indexing Arrays with Boolean Values\n","\n","Numpy can easily create arrays of boolean values and use those to select certain values to extract from an array.\n","\n","Sigma also reports data on the cost of the insured losses of disasters:"]},{"cell_type":"code","metadata":{"id":"a9Ykx-GhHPWT","colab_type":"code","colab":{}},"source":["# Here is the array that represents the cost of all insured losses (in billions) per year from 1996 - 2016\n","\n","disaster_cost = np.array([7.63, 7.03, 6.39, 8.91, 6.54, 37.25, 4.34, \n","                          4.5, 5.06, 7.12, 6.46, 7.12, 9.92, 4.68, \n","                          5.6, 7.72, 6.55, 8.47, 7.6, 10.3, 8.74])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXFDdjmxHVaw","colab_type":"code","colab":{}},"source":["# We want to know if there were disasters that cost more than $5 billion\n","disaster_cost > 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWKfYp0uUBHR","colab_type":"code","colab":{}},"source":["# Let's see the actual costs of disasters that were greater than $5 billion\n","print(disaster_cost[disaster_cost > 5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJdByaHQHx6q","colab_type":"code","colab":{}},"source":["# We want to know all the years cost more than $5 billion dollars\n","# We need to first create an array of all the year\n","years = np.array([1996, 1997, 1998, 1999, 2000, 2001, \n","                  2002, 2003, 2004, 2005, 2006, \n","                  2007, 2008, 2009, 2010, 2011,\n","                  2012, 2013, 2014, 2015, 2016])\n","\n","# Lets find the years\n","print(years[disaster_cost > 5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZaxqSjSpWOWc","colab_type":"code","colab":{}},"source":["# Let's find which years that cost more than $5 billion, but less than $7 billion\n","\n","print(years[(disaster_cost > 5) & (disaster_cost < 7)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bYildQnDAho-","colab_type":"text"},"source":["### Problem #3\n","\n","You will be working with the data you created in Problem #1. "]},{"cell_type":"code","metadata":{"id":"fz_itYE6gCEA","colab_type":"code","colab":{}},"source":["# Print the data you created in Problem #1\n","\n","# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_B8QBS3QDIXz","colab_type":"text"},"source":["3A - Create two separate Numpy arrays for total number of disasters and total number of victims from your original array."]},{"cell_type":"code","metadata":{"id":"_JU1narXDJBV","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6imOc8skHCiC","colab_type":"text"},"source":["3B - In which years were there more than 100,000 victims?\n","\n","Hint: Will we need to use the array for the years?"]},{"cell_type":"code","metadata":{"id":"Cj5ioSmTIGTg","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bzy_XqHeHFcE","colab_type":"text"},"source":["3C - Are there years where there were more than 400 disasters and had more than 75,000 victims? If so, which year(s)?"]},{"cell_type":"code","metadata":{"id":"77e8IMrpINZW","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eb8WkOkTAA6O","colab_type":"text"},"source":["## 1.4 Understanding the axis\n","\n","I want to introduces an important concept when working with NumPy: the axis. This indicates the particular dimension along which a function should operate (provided the function does something taking multiple values and converts to a single value). \n","\n","Let's look at a concrete example with `sum`, which just adds elements together:"]},{"cell_type":"code","metadata":{"id":"tftTDlf7gIb9","colab_type":"code","colab":{}},"source":["# Here is object A again\n","A"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gO5cbUewD97U","colab_type":"code","colab":{}},"source":["# Using the array A we created above, let's add all the elements\n","np.sum(A)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ee9NQjm5EePC","colab_type":"code","colab":{}},"source":["# Double check if that function accurately added all the elements\n","np.sum(A) == (0+1+2+3+4+5+6+7+8+9+10+11)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbXz2iS0E3sB","colab_type":"code","colab":{}},"source":["# Let's add the sum across each of the rows\n","np.sum(A, axis = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zA4sXbyvE_H1","colab_type":"code","colab":{}},"source":["# Let's add the sum across each of the columns\n","np.sum(A, axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f89UQM9GArmB","colab_type":"text"},"source":["### Problem #4\n","\n","From the object you created in problem #2C, find the total number of disasters in seven year intervals:"]},{"cell_type":"code","metadata":{"id":"3q-0TpLFEg_A","colab_type":"code","colab":{}},"source":["# View object from problem 2C"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSm2hZ_PFQrb","colab_type":"code","colab":{}},"source":["# ENTER CORE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P554CFoVfs4O","colab_type":"text"},"source":["# #2. Pandas\n","[Pandas](http://pandas.pydata.org/) is a an open source library providing high-performance, easy-to-use data structures and data analysis tools. Pandas is particularly suited to the analysis of _tabular_ data, i.e. data that can can go into a table. In other words, if you can imagine the data in an Excel spreadsheet, then Pandas is the tool for the job.\n","\n","### Pandas capabilities (from the Pandas website):\n","\n","* A fast and efficient DataFrame object for data manipulation with integrated indexing;\n","* Flexible reshaping and pivoting of data sets;\n","* Intelligent label-based slicing, fancy indexing, and subsetting of large data sets;\n","* Time series-functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging. Even create domain-specific time offsets and join time series without losing data;\n","* Python with pandas is in use in a wide variety of academic and commercial domains, including Finance, Neuroscience, Economics, Statistics, Advertising, Web Analytics, and more."]},{"cell_type":"markdown","metadata":{"id":"T-SWE5LsFhU6","colab_type":"text"},"source":["### Problem #5\n","\n","Import the `pandas` library named as a `pd` object."]},{"cell_type":"code","metadata":{"id":"bV_yP353Fht8","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pIGP5eqzg3ZY","colab_type":"text"},"source":["## 2.1 Data Structures\n","\n","### 2.1.1 Series\n","\n","A Series represents a one-dimensional array of data. The main difference between a Series and numpy array is that a Series has an _index_. The index contains the labels that we use to access the data, like a date, for example.\n","\n","There are many ways to [create a Series](https://pandas.pydata.org/pandas-docs/stable/dsintro.html#series). We will just show a few."]},{"cell_type":"code","metadata":{"id":"Hc1XhfXiMRGX","colab_type":"code","colab":{}},"source":["# Let's create a series with another disaster reporting data source, Munich RE\n","# Here is the list of years to be the index\n","year = ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003',\n","        '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011',\n","        '2012', '2013', '2014', '2015', '2016']\n","\n","# Here is the number of disasters that occurred each year\n","disaster_counts = [448, 411, 469, 449, 523, 446, 443, 431, 380, 449, 554,\n","                   602, 486, 531, 565, 528, 648, 585, 679, 745, 748]\n","\n","# Create a Series of the number of disasters, indexed by the year it occurred\n","MunichRE_disasters = pd.Series(disaster_counts, index= year)\n","\n","# View the time series data\n","MunichRE_disasters"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b_-2DMlIEBIu","colab_type":"text"},"source":["What's also nice is that arithmetic operations and most `numpy` function can be applied to Series.\n","\n","An important point is that the Series keep their index during such operations.\n","\n"]},{"cell_type":"code","metadata":{"id":"Gh6zVZ1zELAd","colab_type":"code","colab":{}},"source":["# Lets log transform the counts\n","np.log(MunichRE_disasters)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i-HC-lbdEbe0","colab_type":"text"},"source":["We can also access the underlying index object if we need to:"]},{"cell_type":"code","metadata":{"id":"bO0yDmqYPaEt","colab_type":"code","colab":{}},"source":["# We double check the indexes we set\n","MunichRE_disasters.index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SikY4hUElpu","colab_type":"code","colab":{}},"source":["# How many disasters occurred in 2007?\n","MunichRE_disasters['2007']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bSKNKR1Eziq","colab_type":"code","colab":{}},"source":["# Similar function as above, we can also index using the 'loc' function\n","MunichRE_disasters.loc['2007']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XPv4cxBPd1h","colab_type":"code","colab":{}},"source":["# We can also index by the raw position, using the 'iloc' function.\n","# What was the number of disasters that occurred in the 12th observation?\n","MunichRE_disasters.iloc[12]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4olknmZOPzcc","colab_type":"text"},"source":["### Problem #6\n","\n","Here is additional data from MunichRE:\n","\n","|   Year    | Insured Losses ($bn) | \n","|:------:|:------:|\n","| 1996 | \t17.05\t|\t\n","| 1997 |\t7.56\t|\t\n","| 1998 | 25.60 | \n","| 1999 | 36.04 |\n","| 2000 | \t13.25\t |\n","| 2001 | \t15.15\t |\n","| 2002 | \t21.80\t|\n","| 2003 | \t20.85\t|\n","| 2004 | \t49.33\t|\t\n","| 2005 | \t105.35\t|\t\n","| 2006 | \t18.00\t|\t\n","| 2007 | \t26.55\t|\t\n","| 2008 | \t42.69\t|\t\n","| 2009 | \t21.80\t|\n","| 2010 | \t41.74\t|\t\n","| 2011 | \t105.35\t|\n","| 2012 | \t59.78\t|\n","| 2013 | \t33.19\t|\n","| 2014 | \t28.45\t|\t\n","| 2015 | \t30.34\t|\n","| 2016 | \t45.53\t|\t"]},{"cell_type":"markdown","metadata":{"id":"IQ76q3anHOjm","colab_type":"text"},"source":["6A - Create a new time series array object of the insured losses per year using Pandas. Print to see the time series array.\n"]},{"cell_type":"code","metadata":{"id":"J-AZ38T3P15d","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gZFlotfIHSDu","colab_type":"text"},"source":["6B - What was the total insured losses in 2011? (Please use functions from above to show how you got the answer)\n","\n"]},{"cell_type":"code","metadata":{"id":"AauqC2GNHcZ8","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O-vl_2lFPovV","colab_type":"text"},"source":["### 2.1.2 DataFrame\n","\n","There is a lot more to Series, but they are limited to a single \"column\". A more useful Pandas data structure is the DataFrame. \n","\n","A DataFrame is basically a bunch of series that share the same index. It's a lot like a table in a spreadsheet.\n","\n","Let's create a DataFrame using data from problem #4 and #5:\n","\n","|   Year    | # of total disasters| Insured losses ($bn) |\n","|:------:|:------:|:------: |\n","| 1996 | \t448\t|\t17.05 |\n","| 1997 |\t411\t|\t7.56 |\n","| 1998 | 469 | \t25.60 |\n","| 1999 | 449 | 36.04 |\n","| 2000 | \t523\t |\t13.25 |\n","| 2001 | \t446\t |\t15.15 |\n","| 2002 | \t443\t|\t21.80 |\n","| 2003 | \t431\t|\t20.85 |\n","| 2004 | \t380\t|\t49.33 |\n","| 2005 | \t449\t|\t105.35 |\n","| 2006 | \t554\t|\t18.00 |\n","| 2007 | \t602\t|\t26.55 |\n","| 2008 | \t486\t|\t42.69 |\n","| 2009 | \t531\t|\t21.80 |\n","| 2010 | \t565\t|\t41.74 |\n","| 2011 | \t528\t|\t105.35 |\n","| 2012 | \t648\t|\t59.78 |\n","| 2013 | \t585\t|\t33.19 |\n","| 2014 | \t679\t|\t28.45 |\n","| 2015 | \t745\t|\t30.34 |\n","| 2016 | \t748\t|\t45.53 |"]},{"cell_type":"code","metadata":{"id":"hTr__VKVX4fs","colab_type":"code","colab":{}},"source":["# First, we create a dictionary\n","Year = ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003',\n","                 '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011',\n","                 '2012', '2013', '2014', '2015', '2016']\n","MunichRE_data = {'Total_Disasters': [448, 411, 469, 449, 523, 446, 443, 431, 380, 449,\n","                           554, 602, 486, 531, 565, 528, 648, 585, 679, 745, 748],\n","        'Insured_Losses': [17.05, 7.56, 25.6, 36.04, 13.25, 15.15, 21.8, 20.85,\n","                           49.33, 105.35, 18, 26.55, 42.69, 21.80, 41.74, \n","                           105.35, 59.78, 33.19, 28.45, 30.34, 45.53]} \n","\n","# Then, we change the dictionary into a DataFrame\n","MunichRE_data = pd.DataFrame(MunichRE_data, index= Year)\n","\n","# View\n","MunichRE_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d0PArq-bO-YI","colab_type":"text"},"source":["Doesn't the Pandas dataframe look like the table I provided you with?\n","\n","Pandas handles missing data very elegantly, keeping track of it through all calculations. We don't have any missing data in the above DataFrame, but if we thought we did, we could check as follows:"]},{"cell_type":"code","metadata":{"id":"XNe6HoyOI2CH","colab_type":"code","colab":{}},"source":["MunichRE_data.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AefEfT5z4HR_","colab_type":"text"},"source":["We can also determine some summary measures using Pandas."]},{"cell_type":"code","metadata":{"id":"_hRp-RWEYZLI","colab_type":"code","colab":{}},"source":["# Let's view the minimum values per column\n","MunichRE_data.min()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WnTvEGn2YkWR","colab_type":"code","colab":{}},"source":["# Let's calculate the averages per column\n","MunichRE_data.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RG0MKdaMYnnw","colab_type":"code","colab":{}},"source":["# Let's calculate the standard deviations per column\n","MunichRE_data.std()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxPPFp1LYrL5","colab_type":"code","colab":{}},"source":["# To make it even easier, let's calculate summary statistics for each column all at once\n","MunichRE_data.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vN-1HGBOPcWk","colab_type":"text"},"source":["How do we index dataframes through pandas?"]},{"cell_type":"code","metadata":{"id":"OpJ-Em9PY3X4","colab_type":"code","colab":{}},"source":["# We can get the data of one column in two ways. One way:\n","MunichRE_data['Total_Disasters']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZ-sqchPPliY","colab_type":"code","colab":{}},"source":["# Or by syntax\n","MunichRE_data.Total_Disasters"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EVsqqKnGJg6J","colab_type":"text"},"source":["We can also index for specific position in the dataframe. \n","\n","For example, let's see how many total disasters there were in 2008. "]},{"cell_type":"code","metadata":{"id":"10ozjQEzJi5m","colab_type":"code","colab":{}},"source":["MunichRE_data.Total_Disasters['2008']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_2mzx28Y67U","colab_type":"code","colab":{}},"source":["# We can also create new columns\n","# Let's calculate average loss per disaster for each year by dividing total insured losses by total disasters\n","MunichRE_data['AvgLossPerDisaster'] = MunichRE_data.Insured_Losses/MunichRE_data.Total_Disasters\n","\n","# View\n","MunichRE_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KxZfaNtcaCN7","colab_type":"text"},"source":["### Problem #7\n","\n","Here is the Sigma data provided in problem 1 again: \n","\n","|   Year    | # of disasters| # of victims |\n","|:------:|:------:|:------: |\n","| 1996 | \t312\t|\t21276 |\n","| 1997 |\t303\t|\t23323 |\n","| 1998 | 297 | \t45416 |\n","| 1999 | 296 | 62846 |\n","| 2000 | \t299\t |\t14950 |\n","| 2001 | \t298\t |\t35609 |\n","| 2002 | \t287\t|\t22311 |\n","| 2003 | \t322\t|\t78894 |\n","| 2004 | \t355\t|\t242519 |\n","| 2005 | \t421\t|\t101563 |\n","| 2006 | \t367\t|\t32532 |\n","| 2007 | \t360\t|\t22199 |\n","| 2008 | \t334\t|\t240612 |\n","| 2009 | \t308\t|\t14948 |\n","| 2010 | \t345\t|\t304054 |\n","| 2011 | \t341\t|\t34072 |\n","| 2012 | \t326\t|\t14007 |\n","| 2013 | \t327\t|\t27063 |\n","| 2014 | \t344\t|\t12914 |\n","| 2015 | \t357\t|\t26543 |\n","| 2016 | \t355\t|\t10841 |\n","\n","Let's practice working with pandas.\n","\n","7A - Create a pandas DataFrame with Sigma data, with columns named TotalManMadeDisasters and TotalVictims. Print the dataframe to see what it looks like."]},{"cell_type":"code","metadata":{"id":"Vk57saoER4JT","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"InNJxp33Hbww","colab_type":"text"},"source":["7B - In a new column, calculate the average number of victims per disaster for each year\n","\n"]},{"cell_type":"code","metadata":{"id":"jjmpn--ESHml","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4blW-wS4HeZi","colab_type":"text"},"source":["7C - What was the average number of victims in 2014? (Use functions we learned in this problem set to find)\n","\n"]},{"cell_type":"code","metadata":{"id":"pXv8TpDSSU5c","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Rjs9A64hUYZ","colab_type":"text"},"source":["## 2.2 Merging data\n","\n","Pandas supports a wide range of methods for merging different datasets. These are described extensively in the [documentation](https://pandas.pydata.org/pandas-docs/stable/merging.html). Here we just give a few examples.\n","\n","Let's now work with disaster data from EM-Dat. "]},{"cell_type":"code","metadata":{"id":"m3qh_aEwkyyL","colab_type":"code","colab":{}},"source":["# We'll create a pandas DataFrame of # of total disasters per year from 1996 - 2016\n","Year = ['1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003',\n","                 '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011',\n","                 '2012', '2013', '2014', '2015', '2016']\n","EMDat_disasters = {'Total_Disasters': [483, 524, 585, 719, 893, 772, 893, 726, 764,\n","                                     870, 747, 728, 663, 614, 676, 601, 561,\n","                                     544, 553, 600, 522]} \n","EMDat_disasters = pd.DataFrame(EMDat_disasters, index= Year)\n","\n","# View\n","EMDat_disasters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RS7pG_TlZQV","colab_type":"code","colab":{}},"source":["# Here is another pandas DataFrame from EM-Dat that reports insured losses per year from 1996 - 2016\n","EMDat_insuredlosses = {'Insured_Losses': [4.93, 3.76, 11.04, 23.47, 5.71, 6.57, 10.97,\n","                                          12.32, 43.15, 92.27, 7.08, 22.70, 30.92,12.53,\n","                                          29.05, 90.38, 35.57, 23.85, 16.17, 20.38, 36.58]} \n","EMDat_insuredlosses = pd.DataFrame(EMDat_insuredlosses, index= Year)\n","\n","# View\n","EMDat_insuredlosses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Q8owOiLmDlb","colab_type":"code","colab":{}},"source":["# Let's merge these two data sets together\n","merged_EMdat = EMDat_disasters.join(EMDat_insuredlosses)\n","\n","# View\n","merged_EMdat"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cp0XEuN-nCgn","colab_type":"text"},"source":["### Problem #8\n","\n","We want to compare total number of disasters from different reporting agencies. In order to do so, we need to have datasets in one object. \n","\n","Produce one dataframe with the total number of disasters from both MunichRE and EM-Dat by year by first creating pandas DataFrame for each datasets then merging the two. Print the merged dataframe to see what it looks like. \n","\n","Hint: Columns cannot have the same names. Please name the columns so that they indicate the proper disaster reporting source. "]},{"cell_type":"code","metadata":{"id":"-fKubgkHnRpG","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duOpc9cIal7_","colab_type":"text"},"source":["## 2.3 Indexing using Boolean series\n","\n","Like with Numpy arrays, we can also use boolean values to select certain values to extract from a pandas object.\n","\n","Let's use the Munich RE data to see how we can index using Boolean values."]},{"cell_type":"code","metadata":{"id":"IacTv1XFa6uh","colab_type":"code","colab":{}},"source":["# Here is the MunichRE data again:\n","MunichRE_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3AFK1x6xpSF4","colab_type":"code","colab":{}},"source":["# Let's subset the data to show only information for years that had greater than $50 billion insured losses\n","costly = MunichRE_data[MunichRE_data.Insured_Losses > 50]\n","\n","# View\n","costly"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BFXovfgFqLpm","colab_type":"text"},"source":["### Problem #9\n","\n","In the MunichRE data, which years had more than 450 disasters and $20 billion insured losses? Please use code to answer this question. Write the code so that only the years that fit this criteria are shown. "]},{"cell_type":"code","metadata":{"id":"sQxMkKqJrong","colab_type":"code","colab":{}},"source":["# ENTER CODE HERE"],"execution_count":null,"outputs":[]}]}